{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/users/jiangjin/jiangjin_bupt/ASR_CORRECTION/Context_Correction/context/data/zh/AISHELL-1/AISHELL-1_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f_data:\n",
    "    data = f_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0764'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].strip().split(' ')[0].split('S')[1].split('W')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 句子长度统计\n",
    "labels = [item.strip().split(' ')[1] for item in data]\n",
    "records = [item.strip().split(' ')[2] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_length = [len(item) for item in labels]\n",
    "records_length = [len(item) for item in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0  14\n",
      "1  14\n",
      "2  13\n",
      "3  19\n",
      "4  13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labels_length_pd = pd.DataFrame(labels_length)\n",
    "records_length_pd = pd.DataFrame(records_length)\n",
    "print(labels_length_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "count  7176.000000\n",
      "mean     15.599359\n",
      "std       4.312322\n",
      "min       4.000000\n",
      "25%      12.000000\n",
      "50%      15.000000\n",
      "75%      19.000000\n",
      "max      38.000000\n",
      "                 0\n",
      "count  7176.000000\n",
      "mean     15.613573\n",
      "std       4.317398\n",
      "min       4.000000\n",
      "25%      12.000000\n",
      "50%      15.000000\n",
      "75%      19.000000\n",
      "max      38.000000\n"
     ]
    }
   ],
   "source": [
    "labels_length_pd.describe()\n",
    "print(labels_length_pd.describe())\n",
    "records_length_pd.describe()\n",
    "print(records_length_pd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "output.append('utt\\tlabel\\trecord')\n",
    "flag = 0\n",
    "for i in range(len(data)):\n",
    "    item = data[i]\n",
    "    item_list = item.strip().split(' ')\n",
    "    # print(item_list[0])\n",
    "    flag_current = item_list[0].split('S')[1].split('W')[0]\n",
    "    if flag_current != flag:\n",
    "        output.append('<d>')\n",
    "        output.append(item_list[0]+'\\t'+item_list[1]+'\\t'+item_list[2])\n",
    "        flag = flag_current\n",
    "    else:\n",
    "        output.append(item_list[0]+'\\t'+item_list[1]+'\\t'+item_list[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc 长度统计\n",
    "doc = []\n",
    "output = []\n",
    "tmp_doc = []\n",
    "flag = 0\n",
    "for i in range(len(data)):\n",
    "    item = data[i]\n",
    "    item_list = item.strip().split(' ')\n",
    "    # print(item_list[0])\n",
    "    flag_current = item_list[0].split('S')[1].split('W')[0]\n",
    "    if flag_current != flag:\n",
    "        doc.append(tmp_doc)\n",
    "        tmp_doc = []\n",
    "        output.append('<d>')\n",
    "        output.append(item_list[0]+'\\t'+item_list[1]+'\\t'+item_list[2])\n",
    "        flag = flag_current\n",
    "    else:\n",
    "        tmp_doc = tmp_doc + [item_list[1]]\n",
    "        output.append(item_list[0]+'\\t'+item_list[1]+'\\t'+item_list[2])\n",
    "doc.append(tmp_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=doc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一二线城市虽然也处于调整中。',\n",
       " '但因为聚集了过多公共资源。',\n",
       " '为了规避三四线城市明显过剩的市场风险。',\n",
       " '标杆房企必然调整市场战略。',\n",
       " '因此土地储备至关重要。',\n",
       " '中原地产首席分析师张大伟说。',\n",
       " '一线城市土地供应量减少。',\n",
       " '也助推了土地市场的火爆。',\n",
       " '北京仅新增住宅土地供应十宗。',\n",
       " '开发边界将作为城市发展的刚性约定。',\n",
       " '不得超越界限盲目扩张。',\n",
       " '目前挂牌的只有几宗土地。',\n",
       " '再加上近期一二线楼市升温。',\n",
       " '房企对土地的争抢更加积极。',\n",
       " '土地市场体现了房企对一二线市场的看重。',\n",
       " '面包价格会跟风上涨吗。',\n",
       " '成交量环比大幅增加。',\n",
       " '国家统计局的数据显示。',\n",
       " '其中广州深圳甚至出现了多个日光盘。',\n",
       " '零三年到去年。',\n",
       " '市场基数已不可同日而语。',\n",
       " '在市场整体从高速增长进入中高速增长区间的同时。',\n",
       " '一线城市在价格较高的基础上整体回升并领涨全国。',\n",
       " '绝大部分三线城市房价仍然下降。',\n",
       " '一线楼市成交量激增。',\n",
       " '三四线城市依然冷清。',\n",
       " '根据中原地产研究中心最新数据。',\n",
       " '一线城市签约十七万套。',\n",
       " '同比涨幅达到百分之四。',\n",
       " '三线城市签约十六万套。',\n",
       " '四线城市成交量有轻微下调。',\n",
       " '住房城乡建设部政策研究中心主任秦虹表示。',\n",
       " '我国房地产市场过去从体偏紧部分地区过紧。',\n",
       " '总体偏松部分地区过剩。',\n",
       " '当供给远快于需求时。',\n",
       " '很难出现去年那样的楼市暴涨。',\n",
       " '即便是北上广深等供应偏紧的一线城市。',\n",
       " '也有限购政策在控制需求规模。',\n",
       " '从而有利于抑制楼市过快上涨。',\n",
       " '楼市调控供的行政手段宜减不宜加。',\n",
       " '稳增长措施需更全面地考虑化解楼市风险问题。',\n",
       " '楼市调控将去向何方。',\n",
       " '进一步发挥市场在资源配置中的决定性作用。',\n",
       " '楼市调控的行政手段宜减不宜加。',\n",
       " '去行政化。',\n",
       " '随着市场调整的深入。',\n",
       " '一些三线城市取消限购及限贷。',\n",
       " '实施较大幅度的补贴政策。',\n",
       " '当地新建商品住宅的房价多在每平方米三四千元。',\n",
       " '政府出台每平方米补贴五百元的托市政策。',\n",
       " '由于不可能从根本上改变供求关系。',\n",
       " '类似的补贴政策常常是短效刺激。',\n",
       " '会对市场造成新一轮的干扰。',\n",
       " '安徽铜陵结束了当地契税补贴政策。',\n",
       " '当月住宅类商品房成交套数骤跌。',\n",
       " '在经济下行压力加大的背景下。',\n",
       " '稳增长措施需更全面地考虑化解楼市风险问题。',\n",
       " '国务院发展研究中心市场经济研究所副所长邓郁松认为。',\n",
       " '可能引发房价泡沫风险。',\n",
       " '在经济增速放缓阶段运用货币政策工具时。',\n",
       " '基本住房需求得到满足后。',\n",
       " '对绿色高效宜居的高品质住房需求快速上升。',\n",
       " '通过改革和政策调整。',\n",
       " '实现我国房地产市场的平稳运行。',\n",
       " '及时发现产业发展中的倾向性苗头性问题。',\n",
       " '促进战略性新兴产业健康发展。',\n",
       " '有关部门和社会各界积极响应。',\n",
       " '采取了一系列的政策措施。',\n",
       " '促使我国战略性新兴产业发展实现了良好开局。',\n",
       " '战略性新兴产业在各地呈现出集聚蓬勃发展的态势。',\n",
       " '先后出台的战略性新兴产业的政策措施主要有六项。',\n",
       " '在加强宏观引导方面。',\n",
       " '形成了系统完整的规划体系。',\n",
       " '明确了发展目标和重点任务。',\n",
       " '在加大要素支持方面。',\n",
       " '新批复了七只创投基金的设立方案。',\n",
       " '吸引社会资本七亿元。',\n",
       " '在加快体制改革方面。',\n",
       " '组织了第一批七个地区城市开展三网融合试点。',\n",
       " '第二批三网融合试点工作业已启动。',\n",
       " '制定了可再生能源电价附加补贴和配额交易方案。',\n",
       " '发改委双节期间重点关注电商促销行为。',\n",
       " '本报记者王颖春国家发改委近日发出通知。',\n",
       " '相关公司股票走势农产品。',\n",
       " '积极防范和妥善应对市场价格异常波动。',\n",
       " '维护正常的市场价格秩序。',\n",
       " '严厉打击春运期间违规上调票价价外收费等违法行为。',\n",
       " '切实降低农产品流通成本。',\n",
       " '要加强节日期间旅游市场价格监管。',\n",
       " '以及提供服务中的变相涨价或价格欺诈行为。',\n",
       " '构建良好的旅游市场环境。',\n",
       " '要继续开展商贸零售领域价格秩序整治。',\n",
       " '重点关注大型电子商务经营者的促销行为。',\n",
       " '规范降价打折返券赠送等促销行为。',\n",
       " '营造良好的消费环境。',\n",
       " '发改委多渠道筹集保障房建设资金到。',\n",
       " '要加大保障性安居工程建设资计划落实力度。',\n",
       " '二零一二年中央进一步加大了资金支持力度。',\n",
       " '地方政府也要加大资金筹措力度。',\n",
       " '加强建设资金统筹和组织实施工作。',\n",
       " '确保保障性安居工程年度建设任务的完成。',\n",
       " '充分发挥地方政府融资平台作用。',\n",
       " '鼓励引导社会力量参与建设保障性住房及配套设施。',\n",
       " '尽快将中央补助投资和省级配套资金分解下达到市县。',\n",
       " '二零一二保障房建设。',\n",
       " '七千万套保障房多少钢材。',\n",
       " '如何在五天内筹集到七万元。',\n",
       " '各地保障房建设的套数。',\n",
       " '保障房和水利建设概念股。',\n",
       " '发改委将订制战略避免境外投资恶性竞争到。',\n",
       " '新京报讯记者钟晶晶发改委昨日表示。',\n",
       " '政府将制订境外投资总体战略。',\n",
       " '避免中国企业境外恶性竞争。',\n",
       " '并鼓励企业在境外上市。',\n",
       " '加强海外信息监测为企业提供对外投资指导。',\n",
       " '形成一批具有国际竞争力的中国企业。',\n",
       " '十一五期间我国累计境外投资七千亿美元。',\n",
       " '年均增速百分之七。',\n",
       " '单项投资规模日益增大。',\n",
       " '几个亿美元的项目不断出现。',\n",
       " '规划对十二五的投资规模未做预测。',\n",
       " '但在鼓励企业走出去方面释出多个信号。',\n",
       " '鼓励传统纺织家电汽车等一般制造业外移。',\n",
       " '鼓励商业银行去境外开设分支机构。',\n",
       " '政府将完善境外投资统计制度。',\n",
       " '实行全口径统计和动态监测。',\n",
       " '确保境外企业和人员安全。',\n",
       " '但目前还存在服务架构不完善。',\n",
       " '缺乏对外投资长远规划等问题。',\n",
       " '可控是病毒武器最基本的要求。',\n",
       " '它必须尽量做到只针对敌对国家的计算机和网络。',\n",
       " '不能波及和影响其他无关国家甚至本国。',\n",
       " '具有精确的目标定位和识别能力。',\n",
       " '一旦战事结束或出于特殊需要可以实现自毁。',\n",
       " '病毒武器的传染性超强。',\n",
       " '它可以跨硬件平台传染。',\n",
       " '除了普通计算机以外。',\n",
       " '病毒武器的隐蔽性极佳。',\n",
       " '可以实现在敌国网络中的长期潜伏。',\n",
       " '是威力巨大的定时炸弹。',\n",
       " '用电脑进行战争比用核武器还有效。',\n",
       " '核武器并不能征服类似美国这样的国家。',\n",
       " '利用电脑病毒却可以在一秒钟内从银行盗走过亿美元。',\n",
       " '足够使美国失去战争基础因此彻底失败。',\n",
       " '但是病毒武器的出现。',\n",
       " '预示着未来战争模样将完全改变。',\n",
       " '病毒武器被认为是目前最具有代表性的网络武器。',\n",
       " '美国芯片行业兴起并购热潮搜狐科技。',\n",
       " '反映了芯片行业出现整合热潮。',\n",
       " '英特尔是世界头号芯片制造商。',\n",
       " '此次以一百六十七亿美元收购拓朗。',\n",
       " '将创下该公司成立四七年来最大收购交易的记录。',\n",
       " '正在寻求扩大移动市场份额。',\n",
       " '拓朗的主打产品是现场可编程门阵列芯片。',\n",
       " '可供客户为特定任务重新编程。',\n",
       " '应用于汽车医疗等行业。',\n",
       " '英特尔首席执行官布赖恩克尔扎尼奇在一份声明中说。',\n",
       " '合并拓朗之后将推出新的产品。',\n",
       " '满足数据中心和物联网细分市场的用户需求。',\n",
       " '形成高度定制化的集成产品。',\n",
       " '微芯片科技公司表示。',\n",
       " '两家公司是联网汽车的主要芯片供应商。',\n",
       " '今年芯片行业并购交易额在八百亿美元以上。',\n",
       " '半导体行业的大公司正在寻求通过并购。',\n",
       " '扩大它们在新的芯片市场的份额。',\n",
       " '随着个人计算机芯片的需求放慢。',\n",
       " '英特尔需要找到新的增长点。',\n",
       " '高德纳咨询公司分析师马克黄说。',\n",
       " '如今则猛增到一两亿美元。',\n",
       " '解决小小芯片上的连线和物理问题需要大量昂贵设备。',\n",
       " '芯片行业的并购风体现了整个科技行业的一种趋势。',\n",
       " '即一些财大气粗的科技公司自己不创新。',\n",
       " '而是寻求收购规模较小更为灵活的公司。',\n",
       " '反映了芯片行业出现整合热。',\n",
       " '因为难以忍受股价长期被低估。',\n",
       " '中国游戏公司纷纷忙着退市。',\n",
       " '巨人网络盛大游戏以及完美世界均已选择了私有化。',\n",
       " '是这类公司在美国市场估值长期受低估。',\n",
       " '北京商报讯记者王晔君日前。',\n",
       " '裁员二千人是由于销售模式发生改变。',\n",
       " '公司已将原有的直销模式改为经销模式。',\n",
       " '因此需要的人员大幅下降。',\n",
       " '由于去年底制定的销售战略是直销模式。',\n",
       " '所以今年上半年公司在全国各地的员工人数大幅增加。',\n",
       " '由于近期销售模式的调整。',\n",
       " '即由直销模式转变为经销模式。',\n",
       " '公司将更多地依靠经销商进行销售。',\n",
       " '正是由于销售模式的改变。',\n",
       " '汉能直接销售人员大幅度减少。',\n",
       " '汉能发布中期财报披露。',\n",
       " '上半年营业收入二十一点零八亿港元。',\n",
       " '同比减少百分之三十四毛利十四点六一亿港元。',\n",
       " '同比减少约百分之四十六亏损额为五百九十三二万港元。',\n",
       " '而去年同期盈利十六点七六亿港元。',\n",
       " '是自二零一一年借壳上市以来首次出现亏损。',\n",
       " '同时公布了重组计划。',\n",
       " '撤销旗下高端产业集团和产品开发集团。',\n",
       " '并将从总部事业部及各区域公司共裁员二千人。',\n",
       " '汉能曾计划今年底前将这一数字提高到三百家。',\n",
       " '汉能上半年业绩出现大幅下滑。',\n",
       " '当务之急是扭转业绩。',\n",
       " '而由直销模式改为经销模式。',\n",
       " '可以缩减很多人力成本。',\n",
       " '有利于降低公司运营成本。',\n",
       " '但是由于直销改为经销。',\n",
       " '汉能对自身产品的议价能力推广力都将减弱。',\n",
       " '公司已经暂停或终止部分关联交易项目。',\n",
       " '已经花费了一定的资源和成本。',\n",
       " '因此暂停或终止这些项目。',\n",
       " '对本公司的上半年业绩带来了负面影响。',\n",
       " '北京商报讯记者王晔君日前。',\n",
       " '裁员两千人是由。',\n",
       " '他们在训练和比赛过程之中的速度也会逐渐慢下来。',\n",
       " '但是根据国外科学家最新的研究结果。',\n",
       " '通过对脚踝和小腿等部位的强化。',\n",
       " '可以有效的抵消年龄所带来的速度劣势。',\n",
       " '使上年纪的跑者也能保持较快的速度。',\n",
       " '美国东卡罗莱纳大学和维克森林大学的研究者认为。',\n",
       " '脚踝和小腿的能力变弱。',\n",
       " '如果能够加强这方面的锻炼。',\n",
       " '他们会拥有较快的速度。',\n",
       " '研究者们选取了一些年龄大的跑者作为研究对象。',\n",
       " '并让年轻跑者作为参照。',\n",
       " '他们的步频大致相同。',\n",
       " '年龄大跑者的步幅明显短于年轻人。',\n",
       " '使得他们的速度变慢了。',\n",
       " '研究者们选取了十九位跑者。',\n",
       " '年龄从二十三岁到五十九岁。',\n",
       " '身体质量指数平均为二十三点四。',\n",
       " '身材偏瘦而且比较健康。',\n",
       " '跑者从二十多岁到五十九岁。',\n",
       " '步幅长度和跑步速度大约下降了百分之二十。',\n",
       " '脚踝的能力损失了大约百分之四十八。',\n",
       " '按照平时训练的速度进行跑步。',\n",
       " '二十岁的跑者平均每英里耗时八分十八秒。',\n",
       " '而六十岁的跑者每英里耗时十分十八秒。',\n",
       " '已经有过不少关于这方面的研究。',\n",
       " '但是研究对象都是年轻跑者和年老跑者。',\n",
       " '年龄段的复盖范围比较窄。',\n",
       " '最令德维塔感到不可思议的是。',\n",
       " '跑者们随着年龄的增长。',\n",
       " '速度呈现出直线下降。',\n",
       " '速度下降的更加明显。',\n",
       " '很多六七十岁的跑者看到这个研究结果时。',\n",
       " '意思是他们比较认同这个结果。',\n",
       " '研究者们希望年龄大的跑者能够注意脚踝的锻炼。',\n",
       " '但德维塔觉得归根到底还是小腿肌肉的问题。',\n",
       " '尤其是比目鱼肌和腓肠肌。',\n",
       " '这才是产生跑步力量的根源。',\n",
       " '这两种方式的结合能够有效锻炼小腿肌肉。',\n",
       " '对于高年龄跑者来说。',\n",
       " '开始一项新的锻炼方式具有一定的风险性。',\n",
       " '想通过训练提升脚踝和小腿的能力。',\n",
       " '这些常年坚持跑步的人身体质量指数偏低。',\n",
       " '长期跑步可能是一种不需要药物来保持身材的有效方式。',\n",
       " '在二零二二年冬季奥运会的竞选当中。',\n",
       " '北京和张家口最终击败了强大的对手阿拉木图。',\n",
       " '顺利获得了冬奥会的主办权。',\n",
       " '这也是这项冰雪顶级盛事首次来到中国。',\n",
       " '在此次申办冬奥会的过程中。',\n",
       " '我们看到了自身强大的综合实力。',\n",
       " '也看到了在冰雪运动综合实力上的欠缺和不足。',\n",
       " '经历过夏奥会的沉淀。',\n",
       " '加上近几年承办诸多国际性赛事的经验积累。',\n",
       " '在这场亚洲国家锁定胜局的申办博弈中。',\n",
       " '北申办此次冬奥会的价值要远远超过承办本身。',\n",
       " '对于北京申办冬奥会的最终结果。',\n",
       " '我们也应该抱着更加长远和开阔的视角来看待。',\n",
       " '北京申办冬奥强大实力成获胜武器。',\n",
       " '此次北京联手张家口申办冬奥会。',\n",
       " '在与阿拉木图的直接博弈中。',\n",
       " '财政能力和硬件设施的优势是我们最终取胜的关键原因。',\n",
       " '而二零零八年举办夏季奥运会所留下的宝贵遗产。',\n",
       " '也是最终打动国家奥运委会评审团的法宝。',\n",
       " '从经济实力和基础设施建设上看。',\n",
       " '北京和张家口要占据着相当明显的优势。',\n",
       " '北京和张家口两地的生产总值是二万二千七百三十点八亿元。',\n",
       " '而阿拉木图仅为四百亿美元。',\n",
       " '影片将在二零一五年一月在慕尼黑正式开机。',\n",
       " '好莱坞当红明星之前曾被盛传将扮演斯诺登。',\n",
       " '好莱坞当红明星之前曾被盛传将扮演斯诺登。',\n",
       " '他确实拿下了这个角色。',\n",
       " '对男友有什么条件。',\n",
       " '她表示最重要的就是诚恳。',\n",
       " '对于姊弟恋也不排斥。',\n",
       " '搜狐娱乐讯七月十日消息。',\n",
       " '据台湾媒体报道。',\n",
       " '许玮甯最近到法国工作。',\n",
       " '仍在个人社群网站频繁更新动态。',\n",
       " '甚至被外界揣测是因为和阮经天分手后所刺。',\n",
       " '她近日终于在受访时松口公开正解。',\n",
       " '背后意义竟只是不要忘记自己从哪里来。',\n",
       " '搜狐娱乐讯据台湾媒体报道。',\n",
       " '阮经天和许玮甯交往八年屡传婚讯。',\n",
       " '今年三月底惊爆分手。',\n",
       " '当时女方坦承已分居。',\n",
       " '但小天坚持玮甯依然是我的女人。',\n",
       " '有网友日前目击他俩在大稻埕分食炒饭。',\n",
       " '昨天她出席保养品活动。',\n",
       " '松口仍有联络。',\n",
       " '但称自己单身。',\n",
       " '恰巧昨日记者碰见阮经天出门倒垃圾。',\n",
       " '对许玮甯单身说语气落寞表示我没有什么看法。',\n",
       " '搜狐娱乐讯男方和小三还藕断丝连。',\n",
       " '因而痛斩情丝她除了拥有模特儿火辣身材。',\n",
       " '快报讯记者赵丹丹快递实名制时代终于到来了。',\n",
       " '按照国家邮政总局统一部署。',\n",
       " '从下月起全面实施快递实名制登记。',\n",
       " '现代快报记者从省邮政管理局了解到。',\n",
       " '江苏快递实名制登记动真格。',\n",
       " '本周内动员部署全省九零零多家快递企业按要求执行。',\n",
       " '个人寄快递必须登记有效的身份证件。',\n",
       " '本山传媒回应赵本山将有新作品没听说。',\n",
       " '不仅赢得观众好口碑。',\n",
       " '特别是师父赵本山也公开出面为大鹏点赞。',\n",
       " '本月二八日超级月亮和最圆中秋月喜相逢。',\n",
       " '月亮和地球之间的平均距离仅为三五六八九六万公里。',\n",
       " '月亮看起来会比往常大。',\n",
       " '也就是我们常说的超级月亮。',\n",
       " '这一天还将上演月全食。',\n",
       " '超级月亮碰上月全食。',\n",
       " '错过了这次就要到二零三三年了。',\n",
       " '本月下旬天宇将现五星连线奇观。',\n",
       " '中科院紫金山天文台公布了一零月天象。',\n",
       " '现代快报记者注意到。',\n",
       " '天龙座流星雨猎户座流星雨。',\n",
       " '让一零月的天空有点甜蜜蜜的味道。',\n",
       " '水星金星也将迎来观测良机。',\n",
       " '现代快报记者胡玉梅。',\n",
       " '本月中下旬小行星撞地球。',\n",
       " '专家没有科学依据。',\n",
       " '京华时报讯记者任珊记者从北京市教育考试院获悉。',\n",
       " '高招本科二批今天开始进行征集志愿录取。',\n",
       " '一八一所院校将补录一九四九人。',\n",
       " '朱军系阅兵世家曾参与一九八四年阅兵军乐演奏。',\n",
       " '朱圣祎爆王思聪女朋友被诉法官送达起诉书遇阻。',\n",
       " '王思聪将朱圣祎诉至北京朝阳法院。',\n",
       " '要求停止侵权公开道歉赔偿精神损失一元。',\n",
       " '法官送达起诉书副本等应诉材料遇阻。',\n",
       " '朱茵说紫霞仙子谁来演不是我可以决定的。',\n",
       " '资料图片在湖南卫视上周开播的偶像来了中。',\n",
       " '永远的紫霞仙子朱茵的亮相引起粉丝的热捧。',\n",
       " '永远的紫霞仙子朱茵的亮相引起粉丝的热捧。',\n",
       " '来自全球四七个国家和地区的二零零零多名选手参赛。',\n",
       " '机器人服务员现身火锅店顾客直呼女神。',\n",
       " '女神机器人在火锅店内工作。',\n",
       " '机场严查匿打火机过安检放在鞋子里算藏匿。',\n",
       " '本报讯记者杨柳昨天。',\n",
       " '记者从首都机场公安分局航站区派出所获悉。',\n",
       " '首都机场公安分局航站区派出所联合驻场安检人员。',\n",
       " '坚持违法零容忍和高限处理的执法态度。',\n",
       " '严格搜集和固定相关证据。',\n",
       " '近日在违法事实认识清楚法律法规适用明确的基础上。',\n",
       " '依法对一名藏匿打火机过检的旅客进行了行政处罚。',\n",
       " '机场公安加航航班未发生性侵事件。',\n",
       " '网传该航班一名男性旅客对空姐试图性侵导致飞机返航。',\n",
       " '新京报记者从首都国际机场公安分局相关人员处获悉。',\n",
       " '冲突因空姐发餐时餐车碰到了一名旅客。',\n",
       " '双方因语言交流不畅导致纠纷。',\n",
       " '该男子因影响航班正常秩序。',\n",
       " '明星刘晓庆又火了一把。',\n",
       " '她几乎刷遍了各大媒体。',\n",
       " '不是她的戏或是她的八卦。',\n",
       " '而是因为她也中了天价的招。',\n",
       " '机组成功处置深航机上纵火事件获奖二五零万。',\n",
       " '成功处置深航机上纵火事件。',\n",
       " '杀中传女生嫌犯就想找个人发泄。',\n",
       " '其室友在微博上所发的寻人启事。',\n",
       " '警方证实周云露遇害。']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  369\n",
      "1  360\n",
      "2  339\n",
      "3  352\n",
      "4  366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_length = [len(item) for item in doc]\n",
    "import pandas as pd\n",
    "doc_length_pd = pd.DataFrame(doc_length)\n",
    "print(doc_length_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count   20.000000\n",
      "mean   357.800000\n",
      "std      9.649652\n",
      "min    334.000000\n",
      "25%    352.000000\n",
      "50%    360.000000\n",
      "75%    363.000000\n",
      "max    372.000000\n"
     ]
    }
   ],
   "source": [
    "doc_length_pd.describe()\n",
    "print(doc_length_pd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_doc = []\n",
    "for item in doc:\n",
    "    tmp = ''\n",
    "    for it in item:\n",
    "        tmp = tmp + it\n",
    "    str_doc.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0  5773\n",
      "1  5669\n",
      "2  5234\n",
      "3  5487\n",
      "4  5601\n",
      "                 0\n",
      "count    20.000000\n",
      "mean   5582.650000\n",
      "std     179.326305\n",
      "min    5234.000000\n",
      "25%    5453.500000\n",
      "50%    5618.500000\n",
      "75%    5691.000000\n",
      "max    5861.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_length = [len(item) for item in str_doc]\n",
    "import pandas as pd\n",
    "doc_length_pd = pd.DataFrame(doc_length)\n",
    "print(doc_length_pd.head())\n",
    "doc_length_pd.describe()\n",
    "print(doc_length_pd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = '/home/users/jiangjin/jiangjin_bupt/ASR_CORRECTION/Context_Correction/context/data/zh/AISHELL-1/'\n",
    "# with open(output_path+'AISHELL-1_test_doc.txt', 'w') as f_data:\n",
    "#     for item in output:\n",
    "#         f_data.writelines(item)\n",
    "#         f_data.writelines('\\n')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw cer 测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AISHELL-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/users/jiangjin/jiangjin_bupt/ASR_CORRECTION/Context_Correction/context_seq2seq/data/zh/AISHELL-1/AISHELL-1_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f_data:\n",
    "    data = f_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BAC009S0764W0121 甚至出现交易几乎停滞的情况。 甚至出现交易几乎停滞的情况。\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BAC009S0764W0121 甚至出现交易几乎停滞的情况。 甚至出现交易几乎停滞的情况。\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item.strip().split(' ')[1] for item in data]\n",
    "records = [item.strip().split(' ')[2] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/users/jiangjin/.cache/huggingface/modules/datasets_modules/metrics/cer/0d603b79fde740594c09751048122254b33a79b1c45328bd72ca604534ce8156 (last modified on Tue Dec 14 16:32:40 2021) since it couldn't be found locally at cer, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04312092977550674"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = metric.compute(references=labels, predictions=records)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HKUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/users/jiangjin/jiangjin_bupt/ASR_CORRECTION/Context_Correction/context_seq2seq/data/zh/HKUST/HKUST_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f_data:\n",
    "    data = f_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utt\\tlabel\\trecord\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5236"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[1:]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20040503_222707_A000687_B000688-A-000656-001110\\t王保文啊 你是 我姓曾。\\t让我报文我姓张。\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item.strip().split('\\t')[1] for item in data]\n",
    "records = [item.strip().split('\\t')[2] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36506/1992660329.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('cer')\n",
      "Using the latest cached version of the module from /home/users/jiangjin/.cache/huggingface/modules/datasets_modules/metrics/cer/0d603b79fde740594c09751048122254b33a79b1c45328bd72ca604534ce8156 (last modified on Tue Dec 14 16:32:40 2021) since it couldn't be found locally at cer, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2759536885854238"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = metric.compute(references=labels, predictions=records)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3228b2b04fe574edc1cfad377da45b01c8bfafeb5d7448f83b83b0b5984135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
